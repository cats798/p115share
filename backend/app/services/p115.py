from p115client import P115Client, check_response
from p115client.fs import P115FileSystem
from p115client.util import share_extract_payload
from app.core.config import settings
from loguru import logger
import asyncio
import time
from contextlib import asynccontextmanager
from typing import Literal

class P115Service:
    def __init__(self):
        self.client = None
        self.fs = None
        self._task_lock = asyncio.Lock()  # Task mutex
        self._current_task: str | None = None  # Track current task type
        if settings.P115_COOKIE:
            self.init_client(settings.P115_COOKIE)

    def init_client(self, cookie: str):
        try:
            self.client = P115Client(cookie, check_for_relogin=True)
            self.fs = P115FileSystem(self.client)
            logger.info("P115Client and FileSystem initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize P115Client: {e}")
            self.client = None
            self.fs = None

    @asynccontextmanager
    async def _acquire_task_lock(self, task_type: Literal["save_share", "cleanup"]):
        """Acquire task lock with waiting logic"""
        max_wait = 300  # 5 minutes max wait
        start_time = time.time()
        
        while self._task_lock.locked():
            if time.time() - start_time > max_wait:
                raise TimeoutError(f"ç­‰å¾…ä»»åŠ¡é”è¶…æ—¶: {task_type}")
            logger.info(f"â³ {task_type} ä»»åŠ¡ç­‰å¾…ä¸­ï¼Œå½“å‰ä»»åŠ¡: {self._current_task}")
            await asyncio.sleep(5)
        
        async with self._task_lock:
            self._current_task = task_type
            logger.info(f"ğŸ”’ {task_type} ä»»åŠ¡å·²è·å–é”")
            try:
                yield
            finally:
                self._current_task = None
                logger.info(f"ğŸ”“ {task_type} ä»»åŠ¡å·²é‡Šæ”¾é”")

    async def _ensure_save_dir(self):
        """Ensure the save directory exists and return its CID"""
        path = settings.P115_SAVE_DIR or "/åˆ†äº«ä¿å­˜"
        logger.info(f"ğŸ” å¼€å§‹æ£€æŸ¥/åˆ›å»ºä¿å­˜ç›®å½•: {path}")
        
        if not self.client:
            logger.warning("âš ï¸ Client not initialized")
            return 0
        
        try:
            # fs_makedirs_app creates the directory if it doesn't exist
            # and returns the final directory's info
            logger.info(f"ğŸ“ è°ƒç”¨ fs_makedirs_app åˆ›å»ºç›®å½•...")
            resp = await self.client.fs_makedirs_app(path, pid=0, async_=True)
            logger.info(f"ğŸ“‹ fs_makedirs_app å“åº”: {resp}")
            check_response(resp)
            
            # The response structure has 'cid' at the top level (not in 'data')
            # Response format: {'state': True, 'error': '', 'errCode': 0, 'cid': '3358575817564146054'}
            cid = 0
            if "cid" in resp:
                # CID is returned as a string, convert to int
                cid = int(resp["cid"])
                logger.info(f"ğŸ”¢ ä»å“åº”ä¸­æå–åˆ° CID: {cid}")
            elif "data" in resp:
                # Fallback: check if it's in a 'data' field (for compatibility)
                data = resp["data"]
                cid = int(data.get("category_id") or data.get("cid") or data.get("id") or 0)
                logger.info(f"ğŸ”¢ ä» data å­—æ®µä¸­æå–åˆ° CID: {cid}")
            else:
                logger.error(f"âŒ å“åº”ä¸­æ²¡æœ‰ 'cid' æˆ– 'data' å­—æ®µ: {resp}")
                
            if cid == 0:
                logger.error(f"âŒ æ— æ³•ä»å“åº”è·å–æœ‰æ•ˆçš„ CID: {resp}")
                return 0
                
            logger.info(f"âœ… ä¿å­˜ç›®å½•å·²ç¡®è®¤: {path} (CID: {cid})")
            return cid
        except Exception as e:
            logger.error(f"âŒ æ— æ³•ç¡®ä¿ä¿å­˜ç›®å½• {path} å­˜åœ¨: {e}", exc_info=True)
            return 0

    async def save_share_link(self, share_url: str, metadata: dict = None):
        """Save a 115 share link to the configured directory
        
        Args:
            share_url: The 115 share URL to save
            metadata: Optional metadata dict containing description, full_text, photo_id, etc.
        """
        async with self._acquire_task_lock("save_share"):
            if not self.client:
                logger.warning("P115Client not initialized, cannot save link")
                return None
            
            logger.info(f"ğŸ“¥ å¼€å§‹å¤„ç†åˆ†äº«é“¾æ¥: {share_url}")
            try:
                # 1. Extract share/receive codes
                payload = share_extract_payload(share_url)
                
                # 2. Get share snapshot to get file IDs and names
                snap_resp = await self.client.share_snap(payload, async_=True)
                check_response(snap_resp)
                
                items = snap_resp["data"]["list"]
                if not items:
                    logger.warning("åˆ†äº«é“¾æ¥å†…æ²¡æœ‰æ–‡ä»¶")
                    return None
                
                # Extract file/folder IDs and names
                # Files use 'fid', folders use 'cid'
                fids = []
                names = []
                for item in items:
                    # Try to get fid (file) or cid (folder)
                    fid = item.get("fid") or item.get("cid")
                    if fid:
                        fids.append(str(fid))
                        names.append(item.get("n", "æœªçŸ¥"))
                    else:
                        logger.warning(f"Item missing both fid and cid: {item}")
                
                if not fids:
                    logger.error("æœªèƒ½æå–åˆ°ä»»ä½•æœ‰æ•ˆçš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ ID")
                    return None
                
                logger.info(f"ğŸ“¦ æ£€æµ‹åˆ° {len(fids)} ä¸ªé¡¹ç›®: {', '.join(names[:3])}{'...' if len(names) > 3 else ''}")
                
                # 3. Ensure save directory
                to_cid = await self._ensure_save_dir()
                
                # 4. Receive files
                receive_payload = {
                    "share_code": payload["share_code"],
                    "receive_code": payload["receive_code"] or "",
                    "file_id": ",".join(fids),
                    "cid": to_cid
                }
                
                try:
                    recv_resp = await self.client.share_receive(receive_payload, async_=True)
                    check_response(recv_resp)
                    logger.info(f"âœ… é“¾æ¥è½¬å­˜æŒ‡ä»¤å·²å‘é€: {share_url} -> CID {to_cid}")
                except Exception as recv_error:
                    # Check if it's a "file already received" error (errno 4200045)
                    error_msg = str(recv_error)
                    if "4200045" in error_msg or "å·²æ¥æ”¶" in error_msg:
                        logger.warning(f"âš ï¸ æ–‡ä»¶å·²åœ¨ç›®æ ‡ä½ç½®ï¼Œè·³è¿‡è½¬å­˜: {share_url}")
                        # Continue to share creation with existing files
                    else:
                        # Other errors, re-raise
                        raise
                
                return {
                    "status": "success", 
                    "to_cid": to_cid, 
                    "names": names,
                    "share_url": share_url,
                    "metadata": metadata or {}  # Include metadata in return value
                }
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜åˆ†äº«é“¾æ¥å¤±è´¥", exc_info=True)
                return None

    async def create_share_link(self, save_result: dict):
        if not self.client or not save_result:
            return None
            
        to_cid = save_result.get("to_cid")
        names = save_result.get("names", [])
        
        try:
            # 5. Wait for 10 seconds as requested
            logger.info(f"â³ ç­‰å¾… 10 ç§’ä»¥ç¡®ä¿æ–‡ä»¶ä¿å­˜å®Œæˆ...")
            await asyncio.sleep(10)
            
            # 6. Find the new file IDs in the destination folder
            # Note: 115 might not have finished the transfer even after 10s for large files,
            # but we try our best.
            new_fids = []
            
            # Use self.client.fs_files or self.fs.iterdir
            # For simplicity and robustness, let's use the raw API or the fs object
            items_iterator = self.fs.iterdir(to_cid, async_=True)
            async for item in items_iterator:
                if item["name"] in names:
                    new_fids.append(str(item["id"]))
            
            if not new_fids:
                logger.warning("âš ï¸ åœ¨ä¿å­˜ç›®å½•ä¸­æœªæ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶ï¼Œå¯èƒ½ä¿å­˜å°šæœªå®Œæˆæˆ–åç§°ä¸åŒ¹é…")
                return None
            
            # 7. Create new share (Standard 15-day share first)
            logger.info(f"ğŸ“¤ æ­£åœ¨ä¸ºä¿å­˜çš„æ–‡ä»¶åˆ›å»ºåˆå§‹åˆ†äº«: {', '.join(names[:3])}...")
            send_resp = await self.client.share_send(",".join(new_fids), async_=True)
            check_response(send_resp)
            
            # Extract share_code to update it to long-term
            data = send_resp["data"]
            share_code = data.get("share_code")
            receive_code = data.get("receive_code") or data.get("recv_code")
            
            if share_code:
                # 8. Update share to be permanent (share_duration=-1)
                logger.info(f"ğŸ”„ æ­£åœ¨å°†åˆ†äº«é“¾æ¥ {share_code} è½¬æ¢ä¸ºé•¿æœŸæœ‰æ•ˆ...")
                update_payload = {
                    "share_code": share_code,
                    "share_duration": -1
                }
                update_resp = await self.client.share_update(update_payload, async_=True)
                check_response(update_resp)
                logger.debug(f"Share update response: {update_resp}")

            new_share = f"https://115.com/s/{share_code}"
            if receive_code:
                new_share += f"?password={receive_code}"
                
            logger.info(f"ğŸ”— é•¿æœŸåˆ†äº«é“¾æ¥å·²ç”Ÿæˆ: {new_share}")
            return new_share
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ–°åˆ†äº«é“¾æ¥å¤±è´¥: {e}")
            return None

    async def cleanup_save_directory(self):
        """Clean up the save directory"""
        async with self._acquire_task_lock("cleanup"):
            logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†ä¿å­˜ç›®å½•...")
            try:
                save_dir_cid = await self._ensure_save_dir()
                if not save_dir_cid:
                    logger.error("æ— æ³•è·å–ä¿å­˜ç›®å½• CID")
                    return False
                
                logger.info(f"ğŸ” å‡†å¤‡æŸ¥è¯¢ä¿å­˜ç›®å½•å†…å®¹ï¼ŒCID: {save_dir_cid} (ç±»å‹: {type(save_dir_cid)})")
                
                # Get all files in save directory (ä½¿ç”¨ app API)
                # æ³¨æ„ï¼šå¿…é¡»ä½œä¸ºä½ç½®å‚æ•°ä¼ é€’ï¼Œä¸èƒ½ä½¿ç”¨ cid= å…³é”®å­—å‚æ•°
                resp = await self.client.fs_files_app(save_dir_cid, async_=True)
                logger.debug(f"ğŸ“‹ fs_files_app å®Œæ•´å“åº”: {resp}")
                files = resp.get("data", [])
                
                if not files:
                    logger.info("âœ… ä¿å­˜ç›®å½•ä¸ºç©ºï¼Œæ— éœ€æ¸…ç†")
                    return True
                
                # Delete all files and folders
                file_ids = []
                for f in files:
                    file_name = f.get("fn") or f.get("n") or f.get("name") or "Unknowné¡¹ç›®"
                    # According to 115 app API response structure:
                    # - Folders: have 'fid' field containing the folder ID (string)
                    # - Files: have 'file_id' field
                    fid = None
                    is_folder = False
                    
                    # Check if it has file_id (it's a file)
                    if "file_id" in f:
                        fid = f["file_id"]
                        is_folder = False
                    # Otherwise, use fid (it's a folder)
                    elif "fid" in f:
                        fid = f["fid"]
                        is_folder = True
                    
                    if fid:
                        file_ids.append(str(fid))
                        logger.debug("ğŸ“ å‘ç°å¯æ¸…ç†é¡¹ç›®: {} (ID: {}, ç±»å‹: {})", file_name, fid, "æ–‡ä»¶å¤¹" if is_folder else "æ–‡ä»¶")
                    else:
                        logger.warning("âš ï¸ æ— æ³•è·å–é¡¹ç›®çš„ ID: {}", f)
                
                if not file_ids:
                    logger.info("âœ… æœªå‘ç°å¯æ¸…ç†çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹")
                    return True
                
                # è°ƒç”¨åˆ é™¤æ¥å£ (ä½¿ç”¨ app API ä¿æŒä¸€è‡´)
                logger.info(f"ğŸ—‘ï¸ å‡†å¤‡åˆ é™¤ {len(file_ids)} ä¸ªé¡¹ç›®: {file_ids}")
                delete_resp = await self.client.fs_delete_app(",".join(file_ids), async_=True)
                logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ¥å£å“åº”: {delete_resp}")
                
                try:
                    check_response(delete_resp)
                    logger.info("âœ… æ¸…ç†ä¿å­˜ç›®å½•æˆåŠŸï¼Œåˆ é™¤äº† {} ä¸ªé¡¹ç›®", len(file_ids))
                    return True
                except Exception as delete_error:
                    # Check for specific error codes
                    error_str = str(delete_error)
                    # errno 231011 means files already deleted
                    if "231011" in error_str:
                        logger.warning(f"âš ï¸ éƒ¨åˆ†é¡¹ç›®å·²åœ¨ 115 ç«¯è¢«åˆ é™¤: {delete_error}")
                        logger.info("âœ… æ¸…ç†å®Œæˆï¼ˆé¡¹ç›®å·²è¢«åˆ é™¤ï¼‰")
                        return True
                    else:
                        logger.error(f"âŒ åˆ é™¤å¤±è´¥: {delete_error}")
                        raise
            except Exception as e:
                logger.error("âŒ æ¸…ç†ä¿å­˜ç›®å½•å¤±è´¥: {}", e)
                return False

    async def cleanup_recycle_bin(self):
        """Empty the recycle bin"""
        async with self._acquire_task_lock("cleanup"):
            logger.info("ğŸ—‘ï¸ å¼€å§‹æ¸…ç©ºå›æ”¶ç«™...")
            try:
                # Prepare payload with optional password
                payload = {}
                if settings.P115_RECYCLE_PASSWORD:
                    payload["password"] = settings.P115_RECYCLE_PASSWORD
                    logger.debug("ä½¿ç”¨å›æ”¶ç«™å¯†ç ")
                
                # Call recycle bin cleanup API
                resp = await self.client.recyclebin_clean_app(payload, async_=True)
                check_response(resp)
                
                logger.info("âœ… å›æ”¶ç«™å·²æ¸…ç©º")
                return True
            except Exception as e:
                logger.error("âŒ æ¸…ç©ºå›æ”¶ç«™å¤±è´¥: {}", e)
                return False

p115_service = P115Service()

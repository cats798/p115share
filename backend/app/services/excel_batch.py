import asyncio
import random
import io
import pandas as pd
from datetime import datetime
from loguru import logger
from sqlalchemy import select, update, delete, func
from app.core.database import async_session
from app.models.schema import ExcelTask, ExcelTaskItem
from app.services.p115 import p115_service
from app.services.tg_bot import tg_service
from app.core.config import settings

class ExcelBatchService:
    def __init__(self):
        self.worker_task = None
        self.active_task_id = None
        self._lock = asyncio.Lock()

    def _read_csv(self, content: bytes):
        """Try reading CSV with multiple encodings"""
        for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb18030']:
            try:
                return pd.read_csv(io.BytesIO(content), encoding=encoding)
            except UnicodeDecodeError:
                continue
            except Exception as e:
                raise e
        raise Exception("æ— æ³•è¯†åˆ«CSVæ–‡ä»¶ç¼–ç ï¼Œè¯·ç¡®ä¿æ–‡ä»¶æ˜¯ UTF-8 æˆ– GBK æ ¼å¼")

    async def parse_file(self, content: bytes, filename: str):
        """Parse Excel/CSV/JSON file and return headers and sample data"""
        try:
            if filename.endswith('.json'):
                data = self._parse_telegram_json(content)
                df = pd.DataFrame(data)
            elif filename.endswith('.csv'):
                df = self._read_csv(content)
            else:
                df = pd.read_excel(io.BytesIO(content))
            
            headers = df.columns.tolist()
            # Convert NaN to None for JSON serialization
            df_cleaned = df.where(pd.notnull(df), None)
            preview_data = df_cleaned.head(5).to_dict(orient='records')
            
            return {
                "headers": headers,
                "preview": preview_data,
                "total_rows": len(df)
            }
        except Exception as e:
            logger.error(f"è§£ææ–‡ä»¶å¤±è´¥ {filename}: {e}")
            raise Exception(f"è§£ææ–‡ä»¶å¤±è´¥: {str(e)}")

    builder_functions = {
        'bold': lambda t: t,
        'italic': lambda t: t,
        'underline': lambda t: t,
        'strikethrough': lambda t: t,
        'code': lambda t: t,
        'pre': lambda t: t,
        'text_link': lambda t: t,
        'mention': lambda t: t,
        'hashtag': lambda t: t,
        'cashtag': lambda t: t,
        'bot_command': lambda t: t,
        'email': lambda t: t,
        'phone_number': lambda t: t,
        'blockquote': lambda t: t,
        'spoiler': lambda t: t,
    }

    def _parse_telegram_json(self, content: bytes):
        """Parse Telegram export JSON and extract links, titles, and original message format"""
        import json
        import re
        
        try:
            data = json.loads(content)
            messages = data.get('messages', [])
            extracted_data = []
            
            # Regex for 115 links: 115.com/s/ or 115cdn.com/s/
            link_pattern = re.compile(r'https?://(?:115\.com|115cdn\.com)/s/([a-z0-9]+)(?:\?password=([a-z0-9]+))?')
            
            for msg in messages:
                text_entities = msg.get('text_entities', [])
                if not text_entities:
                    continue
                    
                # 1. Reconstruct full_text and entities for the message
                full_text = ""
                entities = []
                
                # We need to track the current offset in UTF-16 code units
                def get_u16_len(s):
                    return len(s.encode('utf-16-le')) // 2

                current_offset = 0
                for entity in text_entities:
                    entity_text = entity.get('text', '')
                    entity_type = entity.get('type')
                    
                    if not entity_text:
                        continue
                        
                    length = get_u16_len(entity_text)
                    
                    # Mapping Telegram types to Aiogram types
                    tg_to_aio = {
                        'bold': 'bold',
                        'italic': 'italic',
                        'underline': 'underline',
                        'strikethrough': 'strikethrough',
                        'code': 'code',
                        'pre': 'pre',
                        'text_link': 'text_link',
                        'mention': 'mention',
                        'hashtag': 'hashtag',
                        'cashtag': 'cashtag',
                        'bot_command': 'bot_command',
                        'email': 'email',
                        'phone_number': 'phone_number',
                        'blockquote': 'blockquote',
                        'spoiler': 'spoiler',
                    }
                    
                    if entity_type in tg_to_aio:
                        ent_data = {
                            "type": tg_to_aio[entity_type],
                            "offset": current_offset,
                            "length": length
                        }
                        if entity_type == 'text_link':
                            ent_data["url"] = entity.get('href')
                        
                        entities.append(ent_data)
                    
                    full_text += entity_text
                    current_offset += length

                # 2. Extract specific 115 links from the reconstructed entities
                title = None
                # First bold entity as title fallback
                for entity in text_entities:
                    if entity.get('type') == 'bold' and not title:
                        title = entity.get('text', '').strip()
                        title = re.sub(r'^[ğŸ¬ğŸ¥ğŸï¸ğŸ“€ğŸ“]\s*', '', title)
                        break

                for entity in text_entities:
                    if entity.get('type') == 'text_link':
                        href = entity.get('href', '')
                        match = link_pattern.search(href)
                        if match:
                            share_code = match.group(1)
                            password = match.group(2)
                            
                            current_title = title or f"Message_{msg.get('id')}"

                            extracted_data.append({
                                "é“¾æ¥": href,
                                "æ ‡é¢˜": current_title,
                                "æå–ç ": password or "",
                                "item_metadata": {
                                    "full_text": full_text,
                                    "entities": entities
                                }
                            })
            
            if not extracted_data:
                raise Exception("æœªåœ¨ JSON æ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„ 115 åˆ†äº«é“¾æ¥")
            
            return extracted_data
        except Exception as e:
            logger.exception(f"è§£æ Telegram JSON å¤±è´¥")
            raise Exception(f"è§£æ Telegram JSON å¤±è´¥: {str(e)}")

    async def create_task(self, filename: str, mapping: dict, content: bytes):
        """Create task and items based on mapping"""
        try:
            if filename.endswith('.json'):
                data = self._parse_telegram_json(content)
                df = pd.DataFrame(data)
            elif filename.endswith('.csv'):
                df = self._read_csv(content)
            else:
                df = pd.read_excel(io.BytesIO(content))
            
            df = df.where(pd.notnull(df), None)
            
            link_col = mapping.get('link')
            title_col = mapping.get('title')
            code_col = mapping.get('code')
            
            if not link_col:
                raise Exception("æœªæŒ‡å®šé“¾æ¥åˆ—")

            async with async_session() as session:
                task = ExcelTask(
                    name=filename,
                    status="wait",
                    total_count=len(df)
                )
                session.add(task)
                await session.flush()
                
                # Add items
                for idx, row in df.iterrows():
                    item = ExcelTaskItem(
                        task_id=task.id,
                        row_index=int(idx) + 1,
                        original_url=str(row[link_col]) if row[link_col] else "",
                        title=str(row[title_col]) if title_col and row[title_col] else None,
                        extraction_code=str(row[code_col]) if code_col and row[code_col] else None,
                        item_metadata=row.get('item_metadata') if 'item_metadata' in row else None,
                        status="å¾…å¤„ç†"
                    )
                    session.add(item)
                
                await session.commit()
                return task.id
        except Exception as e:
            logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}")
            raise e

    async def start_worker(self):
        if self.worker_task and not self.worker_task.done():
            return
        self.worker_task = asyncio.create_task(self._worker())
        logger.info("Excel æ‰¹é‡è½¬å­˜æœåŠ¡å·¥ä½œçº¿ç¨‹å¯åŠ¨")

    async def _worker(self):
        while True:
            try:
                item_id = None
                # Check for tasks that are "running"
                async with async_session() as session:
                    result = await session.execute(
                        select(ExcelTask).where(ExcelTask.status == "running").limit(1)
                    )
                    task = result.scalar_one_or_none()
                    
                    if not task:
                        # If no running task, check for "queued" tasks
                        result = await session.execute(
                            select(ExcelTask).where(ExcelTask.status == "queued").order_by(ExcelTask.created_at).limit(1)
                        )
                        task = result.scalar_one_or_none()
                        if task:
                            # Start the queued task
                            task.status = "running"
                            await session.commit()
                            logger.info(f"é˜Ÿåˆ—ä»»åŠ¡ {task.id} ({task.name}) å¼€å§‹è¿è¡Œ")
                
                    if not task:
                        # If no running taskFound, exit worker
                        logger.info("Excel æ‰¹é‡è½¬å­˜æœåŠ¡å·¥ä½œçº¿ç¨‹é€€å‡ºï¼ˆæ— è¿è¡Œä¸­çš„ä»»åŠ¡ï¼‰")
                        self.worker_task = None
                        break
                    
                    self.active_task_id = task.id
                    interval_min = task.interval_min
                    interval_max = task.interval_max
                    
                    try:
                        # Get one pending item
                        async with async_session() as session:
                            result = await session.execute(
                                select(ExcelTaskItem).where(
                                    ExcelTaskItem.task_id == task.id,
                                    ExcelTaskItem.status == "å¾…å¤„ç†"
                                ).order_by(ExcelTaskItem.row_index).limit(1)
                            )
                            item = result.scalar_one_or_none()
                            
                            if item:
                                item.status = "å¤„ç†ä¸­"
                                item_id = item.id
                                # Update current_row in ExcelTask and set is_waiting to False
                                await session.execute(
                                    update(ExcelTask).where(ExcelTask.id == task.id).values(
                                        current_row=item.row_index,
                                        is_waiting=False
                                    )
                                )
                                await session.commit()
                            else:
                                # No more pending items for this task
                                await session.execute(
                                    update(ExcelTask).where(ExcelTask.id == task.id).values(
                                        status="completed", 
                                        current_row=0,
                                        is_waiting=False
                                    )
                                )
                                await session.commit()
                                self.active_task_id = None
                                continue

                        # Process the item
                        if p115_service.is_restricted:
                            logger.info(f"â³ P115 æœåŠ¡å½“å‰å¤„äºå—é™çŠ¶æ€ï¼Œæ‰¹é‡ä»»åŠ¡ {task.id} æš‚åœç­‰å¾…...")
                            # å°† item çŠ¶æ€æ”¹å›å¾…å¤„ç†ï¼Œä»¥ä¾¿ç¨åé‡è¯•
                            async with async_session() as session:
                                await session.execute(
                                    update(ExcelTaskItem).where(ExcelTaskItem.id == item_id).values(status="å¾…å¤„ç†")
                                )
                                await session.commit()
                            await asyncio.sleep(600)  # ç­‰å¾… 10 åˆ†é’Ÿå†é‡çœ‹
                            continue

                        await self._process_item(item_id)
                        
                    finally:
                        # Find next row and set is_waiting to True before sleep
                        if item_id:
                            async with async_session() as session:
                                # Look ahead for next pending item
                                next_result = await session.execute(
                                    select(ExcelTaskItem.row_index).where(
                                        ExcelTaskItem.task_id == task.id,
                                        ExcelTaskItem.status == "å¾…å¤„ç†"
                                    ).order_by(ExcelTaskItem.row_index).limit(1)
                                )
                                next_row = next_result.scalar_one_or_none()
                                
                                if next_row:
                                    await session.execute(
                                        update(ExcelTask).where(ExcelTask.id == task.id).values(
                                            current_row=next_row,
                                            is_waiting=True
                                        )
                                    )
                                else:
                                    await session.execute(
                                        update(ExcelTask).where(ExcelTask.id == task.id).values(
                                            current_row=0,
                                            is_waiting=False
                                        )
                                    )
                                await session.commit()
                        self.active_task_id = None
                
                # Rate limiting (Random interval)

                # Rate limiting (Random interval) with capacity check
                interval = random.randint(interval_min, interval_max)
                
                # åˆ©ç”¨ç­‰å¾…æ—¶é—´æ£€æŸ¥å®¹é‡ (ä¸å ç”¨è½¬å­˜æ—¶é—´ï¼Œä¸”æ— é”å†²çª)
                start_check = datetime.now()
                try:
                    # mode="batch" åŒ…å« 10% å…œåº•é€»è¾‘
                    await p115_service.check_capacity_and_cleanup(mode="batch")
                except Exception as ce:
                    logger.error(f"æ‰¹é‡ä»»åŠ¡é—´éš™å®¹é‡æ£€æŸ¥å¤±è´¥: {ce}")
                
                # è®¡ç®—å‰©ä½™éœ€è¦ sleep çš„æ—¶é—´
                elapsed = (datetime.now() - start_check).total_seconds()
                remaining_sleep = interval - elapsed
                
                if remaining_sleep > 0:
                    await asyncio.sleep(remaining_sleep)
                else:
                    logger.debug(f"å®¹é‡æ£€æŸ¥è€—æ—¶ {elapsed:.2f}s > é—´éš” {interval}sï¼Œè·³è¿‡é¢å¤–ç­‰å¾…")
                
            except Exception as e:
                logger.error(f"Excel å·¥ä½œçº¿ç¨‹å‡ºé”™: {e}")
                await asyncio.sleep(5)

    async def _process_item(self, item_id: int):
        async with async_session() as session:
            # Query Item and Task together to get target_channels and keywords
            result = await session.execute(
                select(
                    ExcelTaskItem, 
                    ExcelTask.target_channels,
                    ExcelTask.white_list_keywords,
                    ExcelTask.black_list_keywords
                )
                .join(ExcelTask, ExcelTask.id == ExcelTaskItem.task_id)
                .where(ExcelTaskItem.id == item_id)
            )
            try:
                row = result.one()
                item = row[0]
                target_channels = row[1]
                white_list = row[2]
                black_list = row[3]
            except Exception:
                logger.error(f"Item {item_id} not found or task deleted")
                return

            task_id = item.task_id
            
            # --- Keyword Filtering Logic ---
            search_text = f"{item.title or ''} {item.original_url or ''}"
            if item.item_metadata and isinstance(item.item_metadata, dict):
                search_text += f" {item.item_metadata.get('full_text', '')}"
            
            search_text = search_text.lower()
            
            # 1. Check Blacklist (Blacklist Wins)
            if black_list:
                black_keywords = [k.strip().lower() for k in black_list.split(',') if k.strip()]
                for kw in black_keywords:
                    if kw in search_text:
                        logger.info(f"Item {item.id} skipped (Blacklist match: {kw})")
                        item.status = "è·³è¿‡"
                        item.error_msg = f"å‘½ä¸­é»‘åå•å…³é”®è¯: {kw}"
                        await session.commit()
                        await self._update_task_counts(task_id)
                        return
            
            # 2. Check Whitelist
            if white_list:
                white_keywords = [k.strip().lower() for k in white_list.split(',') if k.strip()]
                if white_keywords:
                    found_white = False
                    for kw in white_keywords:
                        if kw in search_text:
                            found_white = True
                            break
                    
                    if not found_white:
                        logger.info(f"Item {item.id} skipped (Whitelist no match)")
                        item.status = "è·³è¿‡"
                        item.error_msg = "æœªå‘½ä¸­ç™½åå•å…³é”®è¯"
                        await session.commit()
                        await self._update_task_counts(task_id)
                        return
            # --- End Filtering Logic ---
            
            original_url = item.original_url
            if not original_url:
                item.status = "å¤±è´¥"
                item.error_msg = "é“¾æ¥ä¸ºç©º"
                await session.commit()
                await self._update_task_counts(task_id)
                return

            # 1. Check history first
            history_url = await p115_service.get_history_link(original_url)
            if history_url:
                item.status = "æˆåŠŸ"
                import json
                item.new_share_url = json.dumps(history_url) if isinstance(history_url, list) else history_url
                await session.commit()
                await self._update_task_counts(task_id)
                if tg_service:
                    if item.item_metadata:
                        await tg_service.broadcast_to_channels({original_url: history_url}, item.item_metadata, channel_ids=target_channels)
                    else:
                        await tg_service.broadcast_to_channels({original_url: history_url}, {"full_text": f"èµ„æºåç§°ï¼š{item.title or 'æœªçŸ¥'}\nåˆ†äº«é“¾æ¥ï¼š{{{{share_link}}}}"}, channel_ids=target_channels)
                return

            try:
                # Prepare metadata for broadcasting
                if item.item_metadata:
                    metadata = item.item_metadata.copy()
                    metadata["share_url"] = original_url
                else:
                    metadata = {
                        "description": item.title or "Excel Batch Import",
                        "full_text": f"äº‘ç›˜åˆ†äº«\nèµ„æºåç§°ï¼š{item.title or 'æœªçŸ¥'}\nåˆ†äº«é“¾æ¥ï¼š{{{{share_link}}}}",
                        "share_url": original_url
                    }
                
                # Combine password if present for saving
                url_to_save = original_url
                if item.extraction_code and "?password=" not in url_to_save:
                    url_to_save = f"{url_to_save}?password={item.extraction_code}"

                save_res = await p115_service.save_and_share(
                    url_to_save, 
                    metadata=metadata,
                    target_dir=settings.P115_SAVE_DIR
                )
                
                if save_res:
                    if save_res.get("status") == "success":
                        share_link = save_res.get("share_link")
                        recursive_links = save_res.get("recursive_links", [])
                        
                        # åˆå¹¶ä¸»é“¾æ¥å’Œåˆ†å·é“¾æ¥
                        all_links = recursive_links + ([share_link] if share_link else [])
                        
                        if all_links:
                            import json
                            # å¦‚æœåªæœ‰ä¸€ä¸ªé“¾æ¥å­˜å­—ç¬¦ä¸²ï¼Œå¤šä¸ªå­˜ JSON
                            link_to_store = json.dumps(all_links) if len(all_links) > 1 else all_links[0]
                            
                            await p115_service.save_history_link(original_url, all_links)
                            item.new_share_url = link_to_store
                            item.status = "æˆåŠŸ"
                            
                            # Broadcast to channels
                            if tg_service:
                                if item.item_metadata:
                                    await tg_service.broadcast_to_channels({original_url: all_links}, metadata, channel_ids=target_channels)
                                else:
                                    await tg_service.broadcast_to_channels({original_url: all_links}, {"full_text": f"èµ„æºåç§°ï¼š{item.title or 'æœªçŸ¥'}\nåˆ†äº«é“¾æ¥ï¼š{{{{share_link}}}}"}, channel_ids=target_channels)
                        else:
                            item.status = "å¤±è´¥"
                            item.error_msg = "è½¬å­˜æˆåŠŸä½†ç”Ÿæˆåˆ†äº«é“¾æ¥è¿”å›ä¸ºç©º"
                    elif save_res.get("status") == "pending":
                        item.status = "æˆåŠŸ"
                        item.error_msg = "å·²åœ¨115å®¡æ ¸é˜Ÿåˆ—"
                    else:
                        item.status = "å¤±è´¥"
                        item.error_msg = save_res.get("message", "è½¬å­˜å¤±è´¥")
                else:
                    item.status = "å¤±è´¥"
                    item.error_msg = "è½¬å­˜æœåŠ¡æ— å“åº”"
            except Exception as e:
                logger.exception(f"å¤„ç†é¡¹ç›®å¤±è´¥: {item_id}")
                item.status = "å¤±è´¥"
                item.error_msg = str(e)
            
            await session.commit()
            await self._update_task_counts(task_id)

    async def _update_task_counts(self, task_id: int):
        async with async_session() as session:
            # Get success count
            success_count = await session.scalar(
                select(func.count(ExcelTaskItem.id)).where(
                    ExcelTaskItem.task_id == task_id, 
                    ExcelTaskItem.status == "æˆåŠŸ"
                )
            )
            # Get fail count
            fail_count = await session.scalar(
                select(func.count(ExcelTaskItem.id)).where(
                    ExcelTaskItem.task_id == task_id, 
                    ExcelTaskItem.status == "å¤±è´¥"
                )
            )
            
            await session.execute(
                update(ExcelTask).where(ExcelTask.id == task_id).values(
                    success_count=success_count,
                    fail_count=fail_count
                )
            )
            await session.commit()

    async def start_task(self, task_id: int, skip_count: int = 0, interval_min: int = 5, interval_max: int = 10, target_channels: list = None, white_list_keywords: str = None, black_list_keywords: str = None):
        async with async_session() as session:
            # Get currrent status
            result = await session.execute(select(ExcelTask).where(ExcelTask.id == task_id))
            task = result.scalar_one()
            
            # Check if another task is already running
            result = await session.execute(
                select(ExcelTask).where(ExcelTask.status == "running", ExcelTask.id != task_id)
            )
            other_running = result.scalar_one_or_none()
            
            new_status = "queued" if other_running else "running"
            
            # If resume from paused, dont reset skip/pending
            is_resume = task.status == "paused"
            
            # Update intervals and status
            task.interval_min = interval_min
            task.interval_max = interval_max
            task.status = new_status
            if target_channels is not None:
                task.target_channels = target_channels
            
            # Save keywords
            if white_list_keywords is not None:
                task.white_list_keywords = white_list_keywords
            if black_list_keywords is not None:
                task.black_list_keywords = black_list_keywords
            
            if not is_resume:
                task.skip_count = skip_count
                task.current_row = 0
                # Mark first skip_count items as "è·³è¿‡"
                await session.execute(
                    update(ExcelTaskItem).where(
                        ExcelTaskItem.task_id == task_id,
                        ExcelTaskItem.row_index <= skip_count
                    ).values(status="è·³è¿‡", error_msg=None, new_share_url=None)
                )
                # Mark remaining items as "å¾…å¤„ç†"
                await session.execute(
                    update(ExcelTaskItem).where(
                        ExcelTaskItem.task_id == task_id,
                        ExcelTaskItem.row_index > skip_count
                    ).values(status="å¾…å¤„ç†", error_msg=None, new_share_url=None)
                )
            
            await session.commit()
            
            if new_status == "running":
                logger.info(f"ä»»åŠ¡ {task_id} å¼€å§‹è¿è¡Œ")
            else:
                logger.info(f"ä»»åŠ¡ {task_id} å·²è¿›å…¥é˜Ÿåˆ—æ’é˜Ÿ")

        await self._update_task_counts(task_id)
        if new_status == "running":
            await self.start_worker()

    async def shutdown(self):
        """Handle graceful shutdown: pause running tasks, reset queued tasks"""
        logger.info("Excel æ‰¹é‡è½¬å­˜æœåŠ¡æ­£åœ¨å…³é—­ï¼Œæ­£åœ¨ä¿å­˜ä»»åŠ¡çŠ¶æ€...")
        async with async_session() as session:
            # Reset running, pausing, cancelling, and queued tasks to paused
            await session.execute(
                update(ExcelTask).where(
                    ExcelTask.status.in_(["running", "pausing", "cancelling", "queued"])
                ).values(status="paused", is_waiting=False)
            )
            await session.commit()
        
        # Wait for current processing item if any
        wait_start = datetime.now()
        while self.active_task_id is not None:
            await asyncio.sleep(0.1)
            if (datetime.now() - wait_start).total_seconds() > 30:
                logger.warning("Excel shutdown wait timeout")
                break
        
        logger.info("Excel æ‰¹é‡è½¬å­˜æœåŠ¡å·²å…³é—­")


    async def pause_task(self, task_id: int):
        async with async_session() as session:
            # Set to transitional status first
            await session.execute(
                update(ExcelTask).where(ExcelTask.id == task_id).values(status="pausing")
            )
            await session.commit()
        
        # Safety wait: wait until the current item processing finishes
        wait_start = datetime.now()
        while self.active_task_id == task_id:
            await asyncio.sleep(0.1)
            if (datetime.now() - wait_start).total_seconds() > 60:
                logger.warning(f"Pause task {task_id} safety wait timeout")
                break
        
        # Set to final status
        async with async_session() as session:
            await session.execute(
                update(ExcelTask).where(ExcelTask.id == task_id).values(status="paused")
            )
            await session.commit()
        logger.info(f"Task {task_id} paused safely")

    async def cancel_task(self, task_id: int):
        async with async_session() as session:
            # Set to transitional status first
            await session.execute(
                update(ExcelTask).where(ExcelTask.id == task_id).values(status="cancelling")
            )
            await session.commit()
            
        # Safety wait: same as pause
        wait_start = datetime.now()
        while self.active_task_id == task_id:
            await asyncio.sleep(0.1)
            if (datetime.now() - wait_start).total_seconds() > 60:
                break
        
        # Set to final status
        async with async_session() as session:
            await session.execute(
                update(ExcelTask).where(ExcelTask.id == task_id).values(status="cancelled")
            )
            await session.commit()
        logger.info(f"Task {task_id} cancelled safely")

    async def recover_tasks(self):
        """Recover tasks from non-graceful shutdown"""
        logger.info("Excel æ‰¹é‡è½¬å­˜æœåŠ¡æ­£åœ¨è¿›è¡Œæ•…éšœæ¢å¤...")
        async with async_session() as session:
            # 1. Reset tasks that were stuck in active or transitional states
            await session.execute(
                update(ExcelTask).where(
                    ExcelTask.status.in_(["running", "pausing", "cancelling", "queued"])
                ).values(status="paused", is_waiting=False)
            )
            # 2. Reset items that were stuck in "å¤„ç†ä¸­"
            await session.execute(
                update(ExcelTaskItem).where(ExcelTaskItem.status == "å¤„ç†ä¸­").values(status="å¾…å¤„ç†")
            )
            await session.commit()
        logger.info("Excel æ•…éšœæ¢å¤å®Œæˆ")

    async def delete_task(self, task_id: int):
        async with async_session() as session:
            await session.execute(delete(ExcelTaskItem).where(ExcelTaskItem.task_id == task_id))
            await session.execute(delete(ExcelTask).where(ExcelTask.id == task_id))
            await session.commit()

excel_batch_service = ExcelBatchService()

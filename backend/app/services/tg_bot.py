from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.client.session.aiohttp import AiohttpSession
from aiohttp_socks import ProxyConnector
from app.core.config import settings
from app.services.p115 import p115_service
from loguru import logger
import asyncio
import re

class TGService:
    def __init__(self):
        self.bot = None
        self.dp = None
        self.polling_task = None
        self.is_connected = False
        self._lock = asyncio.Lock()
        self._current_polling_id = 0
        self._verify_tasks = []
        if settings.TG_BOT_TOKEN:
            self.init_bot(settings.TG_BOT_TOKEN)

    def init_bot(self, token: str):
        """Synchronous initialization for startup or immediate use. 
        Note: For clean restarts, use restart_polling instead."""
        try:
            # Configure proxy if set
            session = None
            if settings.PROXY_ENABLED and settings.PROXY_HOST and settings.PROXY_PORT:
                proxy_type = settings.PROXY_TYPE.lower()
                auth = f"{settings.PROXY_USER}:{settings.PROXY_PASS}@" if settings.PROXY_USER and settings.PROXY_PASS else ""
                proxy_url = f"{proxy_type}://{auth}{settings.PROXY_HOST}:{settings.PROXY_PORT}"
                session = AiohttpSession(proxy=proxy_url)
                logger.info(f"Telegram Bot using {settings.PROXY_TYPE} proxy: {settings.PROXY_HOST}:{settings.PROXY_PORT}")
                
            self.bot = Bot(token=token, session=session)
            self.dp = Dispatcher()
            self._register_handlers()
            logger.info("Telegram Bot initialized successfully")
            
            # Verify connection asynchronously and track the task
            v_task = asyncio.create_task(self.verify_connection())
            self._verify_tasks.append(v_task)
            # Cleanup finished verify tasks
            v_task.add_done_callback(lambda t: self._verify_tasks.remove(t) if t in self._verify_tasks else None)
        except Exception as e:
            import traceback
            logger.error(f"Failed to initialize Telegram Bot: {e}")
            logger.error(traceback.format_exc())
            self.bot = None
            self.is_connected = False

    async def _cleanup_bot(self, bot_instance=None):
        """Thoroughly clean up specified or current bot instance and its session"""
        target_bot = bot_instance or self.bot
        prefix = f"[Cleanup-Internal]" if bot_instance else f"[Cleanup-Main-ID:{self._current_polling_id}]"
        
        if target_bot:
            try:
                # Log with safe ID access (bot.id is an int)
                bot_id_str = str(getattr(target_bot, 'id', 'unknown'))
                logger.debug(f"{prefix} ğŸ§¹ æ­£åœ¨æ¸…ç† Bot å®ä¾‹ (ID: {bot_id_str[:5]}...)")
                
                # 0. Cancel all pending verify tasks
                num_v = len(self._verify_tasks)
                for vt in self._verify_tasks[:]:
                    if not vt.done():
                        vt.cancel()
                self._verify_tasks.clear()
                if num_v > 0:
                    logger.debug(f"{prefix} å·²å–æ¶ˆ {num_v} ä¸ªéªŒè¯ä»»åŠ¡")
                
                # 1. Webhook Cleanup (best effort, may fail if proxy is broken)
                try:
                    logger.debug(f"{prefix} æ­£åœ¨å°è¯•åˆ é™¤ Webhook...")
                    await asyncio.wait_for(target_bot.delete_webhook(drop_pending_updates=True), timeout=3.0)
                    logger.debug(f"{prefix} âœ… Webhook å·²åˆ é™¤")
                except asyncio.TimeoutError:
                    logger.debug(f"{prefix} Webhook åˆ é™¤è¶…æ—¶ (ä»£ç†å¯èƒ½å·²å¤±æ•ˆ)ï¼Œè·³è¿‡")
                except Exception as ex:
                    logger.debug(f"{prefix} Webhook åˆ é™¤å¤±è´¥ (éè‡´å‘½): {ex}")

                # 2. ç›´æ¥å…³é—­ HTTP ä¼šè¯ (å¼ºåˆ¶æ–­å¼€æ‰€æœ‰ TCP è¿æ¥)
                if hasattr(target_bot, 'session') and target_bot.session:
                    try:
                        logger.debug(f"{prefix} æ­£åœ¨å¼ºåˆ¶å…³é—­ HTTP ä¼šè¯...")
                        await target_bot.session.close()
                        logger.debug(f"{prefix} âœ… HTTP ä¼šè¯å·²å…³é—­ï¼Œæ‰€æœ‰ TCP è¿æ¥å·²æ–­å¼€")
                    except Exception as ex:
                        logger.debug(f"{prefix} HTTP ä¼šè¯å…³é—­å‡ºé”™: {ex}")
            except Exception as e:
                logger.error(f"{prefix} âŒ æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            finally:
                if not bot_instance:
                    self.bot = None
                    self.dp = None
                    self.is_connected = False
                    logger.debug(f"{prefix} çŠ¶æ€å˜é‡å·²é‡ç½®ä¸º None")

    def _get_allowed_chats(self):
        if not settings.TG_ALLOW_CHATS:
            return []
        return [c.strip() for c in settings.TG_ALLOW_CHATS.split(",") if c.strip()]

    def _register_handlers(self):
        self.dp.message(Command("start"))(self.handle_start)
        self.dp.message(Command("help"))(self.handle_help)
        self.dp.message(Command("id"))(self.handle_id)
        self.dp.message()(self.handle_message)

    async def handle_start(self, message: types.Message):
        allowed = self._get_allowed_chats()
        if allowed and str(message.chat.id) not in allowed:
            logger.warning(f"Unauthorized chat access attempt for /start: {message.chat.id}")
            return
        help_text = (
            "ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ P115-Share æœºå™¨äººï¼\n\n"
            "ç›´æ¥å‘é€ 115 åˆ†äº«é“¾æ¥ï¼ˆæ”¯æŒ 115.com, 115cdn.com, anxia.comï¼‰ï¼Œæˆ‘å°†è‡ªåŠ¨ä¸ºä½ ä¿å­˜å¹¶åˆ›å»ºé•¿æœŸåˆ†äº«ã€‚\n\n"
            "ğŸ’¡ å¯ç”¨å‘½ä»¤ï¼š\n"
            "/start - æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯\n"
            "/help - æŸ¥çœ‹è¯¦ç»†ä½¿ç”¨è¯´æ˜\n"
            "/id - è·å–å½“å‰èŠå¤©çš„ ID (ç”¨äºè®¾ç½®ç™½åå•)"
        )
        await message.answer(help_text)

    async def handle_help(self, message: types.Message):
        allowed = self._get_allowed_chats()
        if allowed and str(message.chat.id) not in allowed:
            logger.warning(f"Unauthorized chat access attempt for /help: {message.chat.id}")
            return
        await self.handle_start(message)

    async def handle_id(self, message: types.Message):
        allowed = self._get_allowed_chats()
        if allowed and str(message.chat.id) not in allowed:
            logger.warning(f"Unauthorized chat access attempt for /id: {message.chat.id}")
            return
        await message.answer(f"å½“å‰èŠå¤© ID: `{message.chat.id}`", parse_mode="Markdown")

    async def handle_message(self, message: types.Message):
        # Whitelist check
        allowed = self._get_allowed_chats()
        if allowed and str(message.chat.id) not in allowed:
            logger.warning(f"Unauthorized chat access attempt: {message.chat.id}")
            return

        # Get message content - text from message or caption from photo message
        full_text = message.caption or message.text or ""
        photo = message.photo[-1] if message.photo else None  # Get highest resolution photo
        entities = message.caption_entities or message.entities or []
        
        # Debug logging
        logger.debug(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯ - æ–‡æœ¬é•¿åº¦: {len(full_text)}, å›¾ç‰‡: {bool(photo)}, å®ä½“æ•°é‡: {len(entities)}")
        
        # Extract all URLs from entities (hyperlinks)
        entity_urls = []
        for entity in entities:
            if entity.type == "text_link" and hasattr(entity, 'url'):
                entity_urls.append(entity.url)
            elif entity.type == "url":
                start = entity.offset
                end = entity.offset + entity.length
                url = full_text[start:end]
                entity_urls.append(url)
        
        # 115 Link Detection (Regex)
        link_pattern = r'https?://(?:115\.com|115cdn\.com|anxia\.com)/s/[a-zA-Z0-9]+(?:[\?#][^ \s\n\r"\'<>]+)?'
        
        # Extract links from text and entity URLs
        text_links = re.findall(link_pattern, full_text)
        all_potential_links = text_links + [url for url in entity_urls if re.match(link_pattern, url)]
        
        # Deduplicate while preserving order
        share_urls = []
        seen = set()
        for url in all_potential_links:
            if url not in seen:
                share_urls.append(url)
                seen.add(url)
        
        if not share_urls:
            logger.debug(f"âŒ æœªæ£€æµ‹åˆ° 115 é“¾æ¥ - æ–‡æœ¬: '{full_text[:100]}...', å®ä½“URLs: {entity_urls}")
            if not full_text.startswith("/"):
                await message.answer("âš ï¸ è¯·å‘é€æœ‰æ•ˆçš„ 115 åˆ†äº«é“¾æ¥ã€‚\næ”¯æŒåŸŸå: 115.com, 115cdn.com, anxia.com")
            return

        total_links = len(share_urls)
        logger.info(f"ğŸ¯ å‘ç° {total_links} ä¸ª 115 é“¾æ¥ï¼Œå¼€å§‹æ‰¹é‡å¤„ç†...")
        
        status_msg = await message.answer(f"âŒ›ï¸ æ­£åœ¨å¤„ç† {total_links} ä¸ªé“¾æ¥ï¼Œè¯·ç¨å€™...")
        
        # Prepare metadata entities common logic
        ser_entities = []
        if entities:
            for e in entities:
                try:
                    ser_entities.append(e.model_dump())
                except AttributeError:
                    ser_entities.append(dict(e))

        processed_links = {} # {original_url: share_link}
        
        async def process_single_link(share_url, index, segment_info=None):
            try:
                # 0. Check history first
                history_share_link = await p115_service.get_history_link(share_url)
                
                if history_share_link:
                    logger.info(f"âœ¨ [{index}/{total_links}] å‘ç°å†å²è®°å½•: {share_url}")
                    processed_links[share_url] = history_share_link
                    await message.reply(f"âœ… å¤„ç†æˆåŠŸï¼\né•¿æœŸåˆ†äº«é“¾æ¥ï¼š\n{history_share_link}")
                    await message.reply(f"ğŸ”” é“¾æ¥ä¿å­˜æˆåŠŸï¼\nåŸé“¾æ¥: {share_url}\næ–°åˆ†äº«: {history_share_link}")
                    return True, history_share_link

                # 1. Check queue status
                q_size = p115_service.queue_size
                is_busy = p115_service.is_busy
                if q_size > 0 or is_busy:
                    position = q_size + (1 if is_busy else 0)
                    await message.reply(f"â³ ç³»ç»Ÿç¹å¿™ï¼Œæ‚¨çš„è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ—ï¼ˆå½“å‰æ’åœ¨ç¬¬ {position} ä½ï¼‰ï¼Œè¯·ç¨å€™...")

                # 2. Save link with metadata
                # Use segmented metadata if available
                metadata = {
                    "description": full_text.strip(),
                    "full_text": segment_info["text"] if segment_info else full_text,
                    "photo_id": segment_info["photo_id"] if segment_info else (photo.file_id if photo else None),
                    "share_url": share_url,
                    "entities": segment_info["entities"] if segment_info else ser_entities
                }
                save_res = await p115_service.save_and_share(share_url, metadata=metadata)
                
                if save_res:
                    if save_res.get("status") == "success":
                        share_link = save_res.get("share_link")
                        if share_link:
                            await p115_service.save_history_link(share_url, share_link)
                            processed_links[share_url] = share_link
                            
                            # å¤„ç†é€’å½’ä¿å­˜ä¸­é—´äº§ç”Ÿçš„é“¾æ¥
                            recursive_links = save_res.get("recursive_links", [])
                            if recursive_links:
                                links_text = "\n".join([f"åˆ†å· {idx}: {link}" for idx, link in enumerate(recursive_links, 1)])
                                await message.reply(f"ğŸ“¦ é€’å½’ä¿å­˜ä¸­äº§ç”Ÿçš„ä¸­é—´é“¾æ¥ï¼š\n{links_text}")

                            # Send detailed success messages to sender
                            await message.reply(f"âœ… å¤„ç†æˆåŠŸï¼\né•¿æœŸåˆ†äº«é“¾æ¥ï¼š\n{share_link}")
                            await message.reply(f"ğŸ”” é“¾æ¥ä¿å­˜æˆåŠŸï¼\nåŸé“¾æ¥: {share_url}\næ–°åˆ†äº«: {share_link}")
                            return True, share_link
                    elif save_res.get("status") == "pending":
                        # Audit handled by the polling logic (consistent with current design)
                        logger.info(f"ğŸ” åˆ†äº«é“¾æ¥æ­£åœ¨å®¡æ ¸ä¸­: {share_url}")
                        asyncio.create_task(self.poll_pending_link(message, save_res))
                        return "pending", None
                    elif save_res.get("status") == "error":
                        error_type = save_res.get("error_type")
                        error_msg = save_res.get("message") or "æœªçŸ¥é”™è¯¯"
                        logger.warning(f"âš ï¸ å¤„ç†é“¾æ¥å¤±è´¥ ({error_type}): {error_msg}")
                        return save_res, None
                
                # Generic failure without specific error info
                return {"error_type": "unknown", "message": "å¤„ç†è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯"}, None
            except Exception as e:
                logger.error(f"âŒ å¤„ç†é“¾æ¥å‡ºé”™ {share_url}: {e}")
                return {"error_type": "exception", "message": str(e)}, None

        # Prepare segments for broadcasting
        # We find the positions of all share URLs in the original text (UTF-16)
        text_utf16_len = self._get_utf16_len(full_text)
        link_positions = [] # [(start_u16, end_u16, url)]
        
        # Search for each URL's position to define segment boundaries
        for url in share_urls:
            start_char = full_text.find(url)
            if start_char != -1:
                start_u16 = self._get_utf16_len(full_text[:start_char])
                end_char = start_char + len(url)
                end_u16 = start_u16 + self._get_utf16_len(url)
                link_positions.append((start_u16, end_u16, url))
        
        # Sort by start position
        link_positions.sort()
        
        # Smart segmentation: Find appropriate boundaries that work for both scenarios:
        # - Title before link: "title\nlink\n\ntitle2\nlink2"
        # - Title after link: "link\ntitle\n\nlink2\ntitle2"
        # Strategy: Segment from last boundary to current link, then extend to a natural break point.
        
        last_boundary = 0
        segments = [] # List of (segmented_text, segmented_entities, target_url)
        for idx, pos in enumerate(link_positions):
            start_u16, end_u16, url = pos
            
            # Default: end at current link's end (works for title-before-link)
            seg_end = end_u16
            
            # For non-last links, try to find a better boundary
            if idx < len(link_positions) - 1:
                next_start_u16 = link_positions[idx + 1][0]
                # Get text between current link end and next link start
                between_start_char = len(full_text.encode('utf-16-le')[:end_u16*2].decode('utf-16-le', errors='ignore'))
                between_end_char = len(full_text.encode('utf-16-le')[:next_start_u16*2].decode('utf-16-le', errors='ignore'))
                between_text = full_text[between_start_char:between_end_char]
                
                # Look for double newline as a natural separator
                double_newline_pos = between_text.find('\n\n')
                if double_newline_pos != -1:
                    # Found a paragraph break, split there
                    split_char = between_start_char + double_newline_pos + 2  # +2 to include the \n\n
                    seg_end = self._get_utf16_len(full_text[:split_char])
                else:
                    # No clear separator; use a heuristic
                    # If there's significant content after the link, include some of it
                    if len(between_text.strip()) > 10:
                        # Likely title-after-link scenario, extend to next link start
                        seg_end = next_start_u16
                    # Otherwise keep seg_end = end_u16 (title-before-link)
            else:
                # Last link: extend to end of text
                seg_end = text_utf16_len
            
            slice_text, slice_entities = self._slice_message(full_text, ser_entities, last_boundary, seg_end)
            segments.append({
                "text": slice_text,
                "entities": slice_entities,
                "url": url,
                "photo_id": photo.file_id if photo else None
            })
            last_boundary = seg_end

        # Process links sequentially
        success_count = 0
        pending_count = 0
        failed_count = 0
        failed_details = []  # Store failed link details: [(url, error_msg)]
        
        last_res = None
        for i, url in enumerate(share_urls, 1):
            if total_links > 1:
                await status_msg.edit_text(f"â³ æ­£åœ¨å¤„ç†ç¬¬ {i}/{total_links} ä¸ªé“¾æ¥...")
            
            # Find the segment for this specific URL
            target_segment = next((s for s in segments if s["url"] == url), None)
            
            res, share_link = await process_single_link(url, i, target_segment)
            last_res = res

            if res is True:
                success_count += 1
                # Broadcast this segment IMMEDIATELY
                if target_segment:
                    await self.broadcast_to_channels(
                        {url: share_link}, 
                        {
                            "full_text": target_segment["text"],
                            "entities": target_segment["entities"],
                            "photo_id": target_segment["photo_id"]
                        }
                    )
                else:
                    # URL not found in visible text (e.g. text_link entity),
                    # broadcast with the full original message metadata
                    await self.broadcast_to_channels(
                        {url: share_link},
                        {
                            "full_text": full_text,
                            "entities": ser_entities,
                            "photo_id": photo.file_id if photo else None
                        }
                    )
            elif res == "pending":
                pending_count += 1
            else:
                failed_count += 1
                # Record failure details
                error_msg = "æœªçŸ¥é”™è¯¯"
                if isinstance(res, dict):
                    err_type = res.get("error_type")
                    if err_type == "expired":
                        error_msg = "é“¾æ¥å·²è¿‡æœŸ"
                    elif err_type == "violated":
                        error_msg = "åŒ…å«è¿è§„å†…å®¹"
                    elif res.get("message"):
                        error_msg = res.get("message")
                failed_details.append((url, error_msg))
        
        if total_links == 1:
            if success_count == 1:
                # For single successful link, delete the processing status message to reduce clutter
                try:
                    await status_msg.delete()
                except Exception:
                    pass
            elif pending_count == 1:
                # For single auditing link, use a more friendly message
                await status_msg.edit_text("ğŸ” åˆ†äº«é“¾æ¥æ­£åœ¨å®¡æ ¸ä¸­ï¼Œå°†åœ¨å®¡æ ¸é€šè¿‡åï¼Œè¿›è¡Œä¿å­˜åˆ†äº«å¤„ç†")
            else:
                # For single failed link
                error_text = "âŒ å¤„ç†å®Œæˆï¼Œä½†é“¾æ¥å¤„ç†å¤±è´¥ã€‚"
                if isinstance(last_res, dict):
                    err_type = last_res.get("error_type")
                    if err_type == "expired":
                        error_text = "âš ï¸ åˆ†äº«é“¾æ¥å·²è¿‡æœŸ"
                    elif err_type == "violated":
                        error_text = "ğŸš« åˆ†äº«é“¾æ¥åŒ…å«è¿è§„å†…å®¹"
                    elif last_res.get("message"):
                        error_text = f"âŒ {last_res.get('message')}"
                
                if error_text.startswith("âŒ å¤„ç†å®Œæˆ"):
                    await status_msg.edit_text(f"{error_text}\n\næˆåŠŸ: 0\nâŒ å¤±è´¥: 1")
                else:
                    await status_msg.edit_text(error_text)
        else:
            # Final notification for batch
            result_text = f"âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼\n\næˆåŠŸ: {success_count}\n"
            if pending_count:
                result_text += f"â³ å®¡æ ¸ä¸­ (è½¬æ¢åè‡ªåŠ¨å‘å¸ƒ): {pending_count}\n"
            if failed_count:
                result_text += f"âŒ å¤±è´¥: {failed_count}\n"
                # Add detailed failure information
                if failed_details:
                    result_text += "\nğŸ“‹ å¤±è´¥è¯¦æƒ…ï¼š\n"
                    for idx, (failed_url, error_msg) in enumerate(failed_details, 1):
                        # Shorten URL to make it more readable
                        short_url = failed_url if len(failed_url) <= 50 else failed_url[:47] + "..."
                        result_text += f"{idx}. {error_msg}\n   {short_url}\n"
            
            await status_msg.edit_text(result_text)

        # Broadcast removed from here because it's done segment-wise in the loop

        # Notify admin if configured
        if settings.TG_USER_ID and str(message.chat.id) != str(settings.TG_USER_ID):
            try:
                admin_msg = f"ğŸ“¢ ç”¨æˆ· {message.chat.id} æäº¤äº† {total_links} ä¸ªé“¾æ¥\n\n"
                admin_msg += f"æˆåŠŸ: {success_count}\n"
                if pending_count:
                    admin_msg += f"â³ å®¡æ ¸ä¸­: {pending_count}\n"
                if failed_count:
                    admin_msg += f"âŒ å¤±è´¥: {failed_count}\n"
                    if failed_details:
                        admin_msg += "\nå¤±è´¥è¯¦æƒ…ï¼š\n"
                        for idx, (failed_url, error_msg) in enumerate(failed_details[:3], 1):  # Show max 3 to admin
                            short_url = failed_url if len(failed_url) <= 40 else failed_url[:37] + "..."
                            admin_msg += f"{idx}. {error_msg}: {short_url}\n"
                        if len(failed_details) > 3:
                            admin_msg += f"... è¿˜æœ‰ {len(failed_details) - 3} ä¸ªå¤±è´¥é“¾æ¥"
                
                await self.bot.send_message(settings.TG_USER_ID, admin_msg)
            except Exception as e:
                logger.error(f"Failed to notify admin: {e}")


    async def poll_pending_link(self, message: types.Message, pending_info: dict):
        """Poll the status of a pending link and process it when ready"""
        share_url = pending_info["share_url"]
        metadata = pending_info.get("metadata", {})
        max_attempts = 36  # 3 hours (5 mins * 36)
        interval = 300   # 5 minutes
        
        for attempt in range(1, max_attempts + 1):
            await asyncio.sleep(interval)
            
            logger.info(f"ğŸ”„ æ­£åœ¨è¿›è¡Œç¬¬ {attempt}/{max_attempts} æ¬¡å®¡æ ¸çŠ¶æ€æ£€æŸ¥: {share_url}")
            status_info = await p115_service.get_share_status(share_url)
            
            if status_info is None:
                logger.warning(f"âš ï¸ æ— æ³•è·å–æ£€æŸ¥çŠ¶æ€ï¼Œå°†åœ¨ä¸‹æ¬¡é‡è¯•: {share_url}")
                continue
            
            if status_info["is_prohibited"]:
                logger.warning(f"ğŸš« è½®è¯¢æ£€æµ‹åˆ°é“¾æ¥åŒ…å«è¿è§„å†…å®¹: {share_url}")
                await message.reply(f"ğŸš« é“¾æ¥å®¡æ ¸æœªé€šè¿‡ï¼šæ£€æµ‹åˆ°è¿è§„å†…å®¹ï¼Œæ— æ³•ç»§ç»­å¤„ç†ã€‚\né“¾æ¥: {share_url}")
                await self._delete_pending_task(pending_info.get("db_id"))
                return
                
            if status_info["is_expired"]:
                logger.warning(f"â° è½®è¯¢æ£€æµ‹åˆ°é“¾æ¥å·²è¿‡æœŸ: {share_url}")
                await message.reply(f"â° é“¾æ¥å·²å¤±æ•ˆï¼šåœ¨å®¡æ ¸æœŸé—´è¯¥åˆ†äº«å·²è¿‡æœŸã€‚\né“¾æ¥: {share_url}")
                await self._delete_pending_task(pending_info.get("db_id"))
                return

            if not status_info["is_auditing"]:  # Audit passed
                logger.info(f"ğŸ‰ é“¾æ¥å®¡æ ¸å·²é€šè¿‡ (status: {status_info['share_state']}): {share_url}")
                save_res = await p115_service.save_and_share(share_url, metadata=metadata)
                
                if save_res and save_res.get("status") == "success":
                    logger.info(f"âœ… å®¡æ ¸é€šè¿‡åè½¬å­˜æˆåŠŸ: {share_url}")
                    share_link = save_res.get("share_link")
                    
                    if share_link:
                        await p115_service.save_history_link(share_url, share_link)
                        # Broadcast single successful link from poll
                        await self.broadcast_to_channels({share_url: share_link}, metadata)
                        
                        success_text = f"âœ… å®¡æ ¸å·²é€šè¿‡ï¼é“¾æ¥å¤„ç†å®Œæˆã€‚\nåŸé“¾æ¥: {share_url}\næ–°åˆ†äº«: {share_link}"
                        await message.reply(success_text)
                        
                        if settings.TG_USER_ID and str(message.chat.id) != str(settings.TG_USER_ID):
                            try:
                                await self.bot.send_message(settings.TG_USER_ID, f"ğŸ”” [åå°ä»»åŠ¡] {success_text}")
                            except Exception:
                                pass
                    await self._delete_pending_task(pending_info.get("db_id"))
                    return 
                else:
                    logger.error(f"âŒ å®¡æ ¸é€šè¿‡åè½¬å­˜ä»ç„¶å¤±è´¥: {share_url}")
                    await message.reply(f"âŒ é“¾æ¥å®¡æ ¸å·²é€šè¿‡ï¼Œä½†è‡ªåŠ¨è½¬å­˜å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å°è¯•: {share_url}")
                    await self._delete_pending_task(pending_info.get("db_id"))
                    return
        
        logger.warning(f"â° é“¾æ¥å®¡æ ¸è½®è¯¢è¶…æ—¶ (3å°æ—¶): {share_url}")
        await message.reply(f"â° é“¾æ¥å®¡æ ¸è½®è¯¢è¶…æ—¶ (å·²æŒç»­ 3 å°æ—¶)ï¼Œè¯·ç¨åæ‰‹åŠ¨æ£€æŸ¥: {share_url}")
        await self._delete_pending_task(pending_info.get("db_id"))

    def _slice_message(self, text: str, entities: list, start_u16: int, end_u16: int) -> tuple[str, list]:
        """Slice message and entities to a specific UTF-16 range"""
        # Encode to UTF-16-LE to work with offsets
        u16_text = text.encode('utf-16-le')
        # Each code unit is 2 bytes
        slice_u16 = u16_text[start_u16*2:end_u16*2]
        new_text = slice_u16.decode('utf-16-le')
        
        new_entities = []
        if entities:
            for e in entities:
                is_dict = isinstance(e, dict)
                offset = e.get("offset") if is_dict else e.offset
                length = e.get("length") if is_dict else e.length
                
                # Check if entity is within the slice
                if offset >= start_u16 and (offset + length) <= end_u16:
                    # Fully contained
                    new_offset = offset - start_u16
                    if is_dict:
                        e_copy = e.copy()
                        e_copy["offset"] = new_offset
                        new_entities.append(e_copy)
                    else:
                        e_copy = e.model_dump() if hasattr(e, "model_dump") else dict(e)
                        e_copy["offset"] = new_offset
                        new_entities.append(e_copy)
                elif offset < end_u16 and (offset + length) > start_u16:
                    # Partially contained - slice it
                    o_start = max(offset, start_u16)
                    o_end = min(offset + length, end_u16)
                    new_offset = o_start - start_u16
                    new_length = o_end - o_start
                    if is_dict:
                        e_copy = e.copy()
                        e_copy["offset"] = new_offset
                        e_copy["length"] = new_length
                        new_entities.append(e_copy)
                    else:
                        e_copy = e.model_dump() if hasattr(e, "model_dump") else dict(e)
                        e_copy["offset"] = new_offset
                        e_copy["length"] = new_length
                        new_entities.append(e_copy)
                        
        return new_text, new_entities

    def _get_utf16_len(self, text: str) -> int:
        """Calculate length in UTF-16 code units"""
        return len(text.encode('utf-16-le')) // 2

    async def _post_to_single_channel_batch(self, channel_config: dict, share_links_map: dict, metadata: dict):
        """Post to a single channel with multiple link replacements"""
        channel_id = channel_config.get("id")
        is_concise = channel_config.get("concise", False)
        
        if not channel_id:
            return
            
        full_text = metadata.get("full_text", "")
        photo_id = metadata.get("photo_id")
        entities_raw = metadata.get("entities", [])
        
        from aiogram.types import MessageEntity
        entities = []
        for e in entities_raw:
            if isinstance(e, dict):
                try: entities.append(MessageEntity(**e))
                except Exception: pass
            else:
                entities.append(e)

        try:
            if is_concise:
                for original_url, share_link in share_links_map.items():
                    if isinstance(share_link, list) and len(share_link) > 1:
                        links_text = "\n".join([f"åˆ†å· {i+1}ï¼š{lnk}" for i, lnk in enumerate(share_link)])
                        await self.bot.send_message(channel_id, f"âœ… å¤„ç†æˆåŠŸï¼\n{links_text}")
                    else:
                        actual_link = share_link[0] if isinstance(share_link, list) and share_link else share_link
                        await self.bot.send_message(channel_id, f"âœ… å¤„ç†æˆåŠŸï¼\né“¾æ¥ï¼š{actual_link}")
                return

            # Batch replacement logic
            new_text = full_text
            new_entities = entities
            
            # 1. Replace all URLs (in text and entities)
            for old_url, new_url_val in share_links_map.items():
                if not old_url: continue
                
                # Format list to multi-part links if needed
                if isinstance(new_url_val, list):
                    if len(new_url_val) > 1:
                        new_url = "\n" + "\n".join([f"åˆ†å· {i+1}ï¼š{lnk}" for i, lnk in enumerate(new_url_val)])
                    elif new_url_val:
                        new_url = new_url_val[0]
                    else:
                        new_url = ""
                else:
                    new_url = new_url_val

                new_text, new_entities = self._replace_text_and_adjust_entities(
                    new_text, new_entities, old_url, new_url
                )
            
            # 2. Update all access codes
            new_text, new_entities = self._update_access_codes(new_text, new_entities, share_links_map)

            if photo_id:
                max_len_utf16 = 1024
                current_len_utf16 = self._get_utf16_len(new_text)
                if current_len_utf16 > max_len_utf16:
                    new_text_encoded = new_text.encode('utf-16-le')
                    new_text = new_text_encoded[:max_len_utf16 * 2].decode('utf-16-le', errors='ignore')
                    if new_entities:
                        final_len_utf16 = self._get_utf16_len(new_text)
                        valid_entities = []
                        for e in new_entities:
                            if e.offset < final_len_utf16:
                                if e.offset + e.length > final_len_utf16:
                                    e.length = final_len_utf16 - e.offset
                                valid_entities.append(e)
                        new_entities = valid_entities

                await self.bot.send_photo(
                    channel_id, 
                    photo=photo_id, 
                    caption=new_text,
                    caption_entities=new_entities
                )
            else:
                await self.bot.send_message(
                    channel_id, 
                    text=new_text,
                    entities=new_entities,
                    disable_web_page_preview=False
                )
            logger.info(f"å·²å°†æ¨é€å‘é€è‡³é¢‘é“: {channel_id}")
        except Exception as e:
            logger.error(f"Failed to post to channel {channel_id}: {e}")

    def _update_access_codes(self, text: str, entities: list, share_links_map: dict) -> tuple[str, list]:
        """Update access codes in text to match new links for multiple pairs"""
        from urllib.parse import urlparse, parse_qs
        import re
        
        current_text = text
        current_entities = list(entities)
        
        # Sort original URLs by their appearance in text
        sorted_originals = sorted(share_links_map.keys(), key=lambda url: text.find(url) if url in text else 999999)

        for old_url in sorted_originals:
            share_link_val = share_links_map[old_url]
            # If it's a list (multi-part share), use the first link to parse the password
            # Since all parts usually share the same password setting
            if isinstance(share_link_val, list):
                if not share_link_val:
                    continue
                share_link = share_link_val[0]
            else:
                share_link = share_link_val

            parsed = urlparse(share_link)
            params = parse_qs(parsed.query)
            new_pwd = params.get("password", [""])[0]
            
            if not new_pwd:
                continue

            pwd_patterns = [
                r'((?:è®¿é—®ç |æå–ç |å¯†ç )(?:ï¼š|:|%EF%BC%9A|%3A)\s*)([a-zA-Z0-9]{4})',
                r'((?:%E8%AE%BF%E9%97%AE%E7%A0%81|%E6%8F%90%E5%8F%96%E7%A0%81|%E5%AF%86%E7%A0%81)(?:%EF%BC%9A|%3A)(?:%20)*)([a-zA-Z0-9]{4})'
            ]
            
            search_start = 0
            if old_url in current_text:
                search_start = current_text.find(old_url)
            elif share_link in current_text:
                search_start = current_text.find(share_link)
            
            best_match = None
            best_start = 999999
            
            for pattern in pwd_patterns:
                for match in re.finditer(pattern, current_text[search_start:], flags=re.IGNORECASE):
                    start = search_start + match.start()
                    if start < best_start:
                        best_start = start
                        best_match = match
                
            if best_match:
                prefix, old_code = best_match.groups()
                if old_code != new_pwd:
                    old_str = f"{prefix}{old_code}"
                    new_str = f"{prefix}{new_pwd}"
                    current_text, current_entities = self._replace_text_and_adjust_entities(
                        current_text, current_entities, old_str, new_str
                    )
                    
        return current_text, current_entities

    def _replace_text_and_adjust_entities(self, text: str, entities: list, old_str: str, new_str: str):
        """Helper to replace text and shift entity offsets/lengths accordingly"""
        has_text_match = old_str in text
        
        if not has_text_match:
            # Check if any text_link URL matches
            new_entities = []
            changed = False
            for entity in entities:
                if hasattr(entity, 'url') and entity.url == old_str:
                    entity.url = new_str
                    changed = True
                new_entities.append(entity)
            return text, new_entities

        start_pos_char = text.find(old_str)
        end_pos_char = start_pos_char + len(old_str)
        
        start_pos_u16 = self._get_utf16_len(text[:start_pos_char])
        old_len_u16 = self._get_utf16_len(old_str)
        end_pos_u16 = start_pos_u16 + old_len_u16
        new_len_u16 = self._get_utf16_len(new_str)
        diff_u16 = new_len_u16 - old_len_u16
        
        new_text = text[:start_pos_char] + new_str + text[end_pos_char:]

        new_entities = []
        if entities:
            from aiogram.types import MessageEntity
            for entity in entities:
                is_dict = isinstance(entity, dict)
                e_offset = entity.get("offset") if is_dict else entity.offset
                e_length = entity.get("length") if is_dict else entity.length
                e_url = (entity.get("url") if is_dict else getattr(entity, "url", None))
                e_type = entity.get("type") if is_dict else entity.type
                
                if e_offset >= end_pos_u16:
                    e_offset += diff_u16
                elif e_offset <= start_pos_u16 and (e_offset + e_length) >= end_pos_u16:
                    e_length += diff_u16
                elif e_offset == start_pos_u16 and e_length == old_len_u16:
                    e_length = new_len_u16
                
                if e_url == old_str:
                    e_url = new_str

                new_entities.append(MessageEntity(
                    type=e_type,
                    offset=e_offset,
                    length=e_length,
                    url=e_url,
                    user=entity.get("user") if is_dict else getattr(entity, "user", None),
                    language=entity.get("language") if is_dict else getattr(entity, "language", None),
                    custom_emoji_id=entity.get("custom_emoji_id") if is_dict else getattr(entity, "custom_emoji_id", None)
                ))
        return new_text, new_entities

    async def get_chat_info(self, chat_id: str):
        """Fetch chat info (title, type) from Telegram"""
        if not self.bot:
            return None
        try:
            chat = await self.bot.get_chat(chat_id)
            return {"id": str(chat.id), "title": chat.title, "type": chat.type}
        except Exception as e:
            logger.error(f"Failed to get chat info for {chat_id}: {e}")
            return None

    async def broadcast_to_channels(self, share_links_map: dict, metadata: dict, channel_ids: list = None):
        """Broadcast processed link(s) to all configured and enabled channels
        :param channel_ids: Optional list of channel IDs to filter the broadcast. If None, send to all enabled.
        """
        import json
        channels = []
        try:
            channels = json.loads(settings.TG_CHANNELS)
        except Exception:
            pass
            
        legacy_id = settings.TG_CHANNEL_ID
        if legacy_id and not any(c.get("id") == str(legacy_id) for c in channels):
            channels.append({"id": str(legacy_id), "enabled": True, "concise": False})
            
        enabled_channels = [c for c in channels if c.get("enabled")]
        
        # Filter by specific channel_ids if requested (e.g. for batch tasks)
        if channel_ids is not None:
            target_ids = set(str(cid) for cid in channel_ids)
            enabled_channels = [c for c in enabled_channels if str(c.get("id")) in target_ids]
        
        if not enabled_channels:
            logger.debug(f"æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç›®æ ‡é¢‘é“ (channel_ids={channel_ids})ï¼Œè·³è¿‡å¹¿æ’­")
            return
            
        for chan in enabled_channels:
            is_concise = chan.get("concise", False)
            if is_concise:
                # Concise mode: Every success link gets a separate simple message
                for original_url, share_link in share_links_map.items():
                    temp_meta = metadata.copy()
                    temp_meta["share_url"] = original_url
                    await self._post_to_single_channel(chan, share_link, temp_meta)
            else:
                # Normal mode: Single broadcast with all links replaced
                await self._post_to_single_channel_batch(chan, share_links_map, metadata)

    async def _post_to_single_channel(self, channel_config: dict, share_link: str, metadata: dict):
        """Legacy helper for single link post (still used by poll_pending or concise)"""
        await self._post_to_single_channel_batch(channel_config, {metadata.get("share_url", ""): share_link}, metadata)

    async def _delete_pending_task(self, db_id: int):
        if db_id:
            from app.core.database import async_session
            from app.models.schema import PendingLink
            from sqlalchemy import delete
            async with async_session() as session:
                await session.execute(delete(PendingLink).where(PendingLink.id == db_id))
                await session.commit()

    async def recover_pending_tasks(self):
        from app.core.database import async_session
        from app.models.schema import PendingLink
        from sqlalchemy import select
        async with async_session() as session:
            result = await session.execute(select(PendingLink).where(PendingLink.status == "auditing"))
            tasks = result.scalars().all()
            if tasks:
                for task in tasks:
                    pending_info = {"share_url": task.share_url, "metadata": task.metadata_json, "db_id": task.id}
                    asyncio.create_task(self._recovered_poll(pending_info))

    async def _recovered_poll(self, pending_info: dict):
        class MockMessage:
            def __init__(self, bot, user_id):
                self.bot = bot
                self.chat = type('obj', (object,), {'id': user_id})
            async def reply(self, text):
                try: await self.bot.send_message(self.chat.id, text)
                except Exception: pass
        user_id = settings.TG_USER_ID or "0"
        mock_msg = MockMessage(self.bot, user_id)
        await self.poll_pending_link(mock_msg, pending_info)

    async def verify_connection(self) -> bool:
        if not self.bot:
            self.is_connected = False
            return False
        try:
            me = await self.bot.get_me()
            if me:
                self.is_connected = True
                logger.info(f"âœ… Telegram Bot è¿æ¥éªŒè¯æˆåŠŸ: @{me.username}")
                return True
        except Exception as e:
            self.is_connected = False
            return False
        self.is_connected = False
        return False

    async def start_polling(self):
        if self.dp and self.bot:
            self._current_polling_id += 1
            try:
                await self.dp.start_polling(self.bot, skip_updates=True, handle_signals=False)
            except Exception as e:
                logger.error(f"Polling error: {e}")

    async def stop_polling(self):
        if self.dp:
            try: await self.dp.stop_polling()
            except Exception: pass
        if self.polling_task and not self.polling_task.done():
            try: await asyncio.wait_for(asyncio.shield(self.polling_task), timeout=3.0)
            except asyncio.TimeoutError:
                self.polling_task.cancel()
                try: await self.polling_task
                except: pass
            self.polling_task = None

    async def restart_polling(self):
        async with self._lock:
            await self.stop_polling()
            await self._cleanup_bot()
            await asyncio.sleep(5)
            if not settings.TG_BOT_TOKEN: return
            self.init_bot(settings.TG_BOT_TOKEN)
            if not self.bot: return
            try: await self.bot.delete_webhook(drop_pending_updates=True)
            except: pass
            await asyncio.sleep(2)
            self.polling_task = asyncio.create_task(self.start_polling())

    async def test_send_to_user(self):
        if not self.bot or not settings.TG_USER_ID: return False, "æœªé…ç½®"
        try:
            await self.bot.send_message(settings.TG_USER_ID, "ğŸ”” æµ‹è¯•æˆåŠŸ")
            return True, "æˆåŠŸ"
        except Exception as e: return False, str(e)

    async def test_send_to_channel(self, channel_id: str = None):
        target_id = channel_id or settings.TG_CHANNEL_ID
        if not self.bot or not target_id: return False, "æœªé…ç½®"
        try:
            await self.bot.send_message(target_id, "ğŸ“¢ æµ‹è¯•æˆåŠŸ")
            return True, "æˆåŠŸ"
        except Exception as e: return False, str(e)

tg_service = TGService()
